
import numpy as np
import pandas as pd
import seaborn as sb
import matplotlib.pyplot as plt
import sklearn

from pandas import Series, DataFrame
from pylab import rcParams
from sklearn import preprocessing 

from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.model_selection import cross_val_predict

from sklearn import metrics
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
from sklearn.metrics import precision_score, recall_score

%matplotlib inline
rcParams['figure.figsize']=5,4
sb.set_style('whitegrid')


--import data
address = titanic training data.csv
titanic_training = pd.read_csv(address)
titanic_training.columns = ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']
print(titanic_training.head())

--check missing values

print(titanic_training.info())

--check if survive variable is binary

sb.countplot(x='Survived', data=titanic_training, palette='hls')

---check for missing values - another method

titanic_training.isnull().sum()
titanic_training.describe()

--drop all variables which are not relevant for survival prediction

Name, passengerID and cabin are not relevant and we can drop

titanic_data = titanic_training.drop(['Name', 'Ticket', 'Cabin'], axis=1)
titanic_data.head()

--Imputing missing values ( ages variable has missing values )

sb.boxplot(x='Parch', y='Age', data=titanic_data, palette='hls')

--average age per parch category

Parch_groups = titanic_data.groupby(titanic_data['Parch'])
Parch_groups.mean()

def age_approx(cols):
    Age = cols[0]
    Parch = cols[1]
    
    if pd.isnull(Age):
        if Parch ==0:
            return 32
        elif Parch == 1:
            return 24
        elif Parch == 2:
            return 17
        elif Parch == 3:
            return 33
        elif Parch == 4:
            return 45
        else:
            return 30
        
    else:
        return Age


titanic_data['Age']=titanic_data[['Age','Parch']].apply(age_approx, axis=1)
titanic_data.isnull().sum()

titanic_data.dropna(inplace=True)
titanic_data.reset_index(inplace=True, drop=True)
print(titanic_data.info())

----converting categorical variables to a dummy indicators

from sklearn.preprocessing import LabelEncoder
laber_encoder = LabelEncoder()

gender_cat = titanic_data['Sex']
gender_encoded = label_encoder.fit_transform(gender_cat)
gender_encoded[0:5]
titanic_data.head()

# 1 = male / 0 = female

gender_DF = pd.DataFrame(gender_encoded, columns=['male_gender'])
gender_DF.head()

embarked_cat = titanic_data['Embarked']

embarked_encoded = lablel_encoder.fit_transform(embarked_cat)

embarked_encoded[0:100]

from sklearn.preprocessing import OneHotEncoder
binary_encoder = OneHotEncoder(categories='auto')
embarked_1hot = binary_encoder.fit_transform(embarked_encoded.reshape(-1,1))
embarked_1hot_mat = embarked_1hot.toarray()
embarked_DF = pd.DataFrame(embarked_1hot_mat, columns = ['C', 'Q', 'S'])
embarked_DF.head()

---dropping old Sex and embarked columns and concatenating the new ones created

titanic_data.drop(['Sex', 'Embarked'], axis=1, inplace=True)
titanic_data.head()

titanic_dmy = pd.concat([titanic_data, gender_DF, embarked_DF], axis=1, verify_integrity=True).astype(float)
titanic_dmy[0:5]

----checking for independence between features

sb.heatmap(titanic_dmy.corr())

titanic_dmy.drop(['Fare', 'Pclass'], axis=1, inplace=True)
titanic_dmy.head()

----checking that the dataset size is sufficient

titanic_dmy.info()

X_train, X_test, y_train, y_test = train_test_split(titanic_dmy.drop('Survived', axis=1), titanic_dmy['Survived'], test_size=0.2, random_state=200)

print(X_train.shape)
print(y_train.shape)

X_train[0:5]

----Deploying and evaluating the model

LogReg = LogisticRegression(solver='liblinear')
LogReg.fit(X_train, y_train)

y_pred = LogReg.predict(X_test)


---Model Evaluation

print(classification_report(y_test, y_pred))

---k-fold cross-validation and confusion matrices

y_train_pred = cross_val_predict(LogReg, X_train, y_train, cv=5)
confusion_matrix(y_train, y_train_pred)

precision_score(y_train, y_train_pred)

----Make a test prediction

titanic_dmy[863:864]

test_passenger = np.array([866, 40, 0,0,0,0,0,1]).reshape(1,-1)
print(LogReg.predict(test_passenger))
print(LogReg.predict_proba(test_passenger))








